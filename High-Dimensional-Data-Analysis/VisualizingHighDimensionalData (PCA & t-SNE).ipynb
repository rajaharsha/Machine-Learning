{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing High Dimensional Data Using PCA & t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Data analysis involves exploration by looking into data distribution of certain variables and correlations between variables.\n",
    "\n",
    "2) Visual exploration is very important to comprehend the data and understand quickly.\n",
    "\n",
    "3) Visual representation of data gets difficult with high dimensional data with different variables distribute across different dimensions.\n",
    "\n",
    "4) Understand this high dimensional becomes easier if we can reduce number of dimensions. \n",
    "\n",
    "<b>PCA:</b> Principle Component Analysis<br>\n",
    "<b>t-SNE:</b> t-Distributed Stochastic Neighbor Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "PCA is a linear transformation that finds the \"principal components\", or directions of greatest variance, in a data set. It can be used for dimension reduction among other things. In this exercise we're first tasked with implementing PCA and applying it to a simple 2-dimensional data set to see how it works. Let's start off by loading and visualizing the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1.0, 2.0, 3.0], [2.0, 4.0, 6.0], [3.0, 6.0, 9.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    # compute the covariance matrix\n",
    "    X = np.matrix(X)\n",
    "    cov = (X.T * X) / X.shape[0]\n",
    "    # perform SVD\n",
    "    U, S, V = np.linalg.svd(cov)    \n",
    "    return U, S, V\n",
    "\n",
    "def project_data(X, U, k):  \n",
    "    U_reduced = U[:,:k]\n",
    "    return np.dot(X, U_reduced)\n",
    "\n",
    "def recover_data(Z, U, k):  \n",
    "    U_reduced = U[:,:k]\n",
    "    return np.dot(Z, U_reduced.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[-0.26726124, -0.68796149, -0.6747447 ],\n",
       "         [-0.53452248, -0.47677442,  0.69783369],\n",
       "         [-0.80178373,  0.54717011, -0.24030756]]),\n",
       " array([  6.53333333e+01,   1.27541700e-15,   4.42091896e-16]),\n",
       " matrix([[-0.26726124, -0.53452248, -0.80178373],\n",
       "         [ 0.17708179, -0.84512377,  0.50438859],\n",
       "         [-0.94721353, -0.00717777,  0.32052303]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, S, V = pca(X)  \n",
    "\n",
    "U, S, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing dimension reduction to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Reduced Data: \n",
      "\n",
      "[[ -3.74165739e+00  -1.11022302e-16]\n",
      " [ -7.48331477e+00  -2.22044605e-16]\n",
      " [ -1.12249722e+01  -5.55111512e-16]]\n",
      "\n",
      "***********************\n",
      "Reconstructed Data: \n",
      "\n",
      "[[ 1.  2.  3.]\n",
      " [ 2.  4.  6.]\n",
      " [ 3.  6.  9.]]\n",
      "\n",
      "***********************\n",
      "Approximation Error: \n",
      "\n",
      "2.71039981919e-15\n"
     ]
    }
   ],
   "source": [
    "Z = project_data(X, U, 2)  \n",
    "print ('2D Reduced Data: \\n')\n",
    "print (Z) \n",
    "\n",
    "print ('\\n***********************')\n",
    "\n",
    "X_recovered = recover_data(Z, U, 2)  \n",
    "print ('Reconstructed Data: \\n')\n",
    "print (X_recovered)\n",
    "\n",
    "print ('\\n***********************')\n",
    "print ('Approximation Error: \\n')\n",
    "print (LA.norm(X_recovered-X))  # compute approximation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing dimension reduction to 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Reduced Data: \n",
      "\n",
      "[[ -3.74165739]\n",
      " [ -7.48331477]\n",
      " [-11.22497216]]\n",
      "\n",
      "***********************\n",
      "Reconstructed Data: \n",
      "\n",
      "[[ 1.  2.  3.]\n",
      " [ 2.  4.  6.]\n",
      " [ 3.  6.  9.]]\n",
      "\n",
      "***********************\n",
      "Approximation Error: \n",
      "\n",
      "3.69555874282e-15\n"
     ]
    }
   ],
   "source": [
    "Z = project_data(X, U, 1)  \n",
    "print ('2D Reduced Data: \\n')\n",
    "print (Z) \n",
    "\n",
    "print ('\\n***********************')\n",
    "\n",
    "X_recovered = recover_data(Z, U, 1)  \n",
    "print ('Reconstructed Data: \\n')\n",
    "print (X_recovered)\n",
    "\n",
    "print ('\\n***********************')\n",
    "print ('Approximation Error: \\n')\n",
    "print (LA.norm(X_recovered-X))  # compute approximation error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
